# A simple static site generator, written in Inko.
import builder.html
import markdown
import markdown.html (Filter)
import std.clone (Clone)
import std.crypto.sha2 (Sha256)
import std.fs.file (ReadOnlyFile, WriteOnlyFile)
import std.fs.path (Path)
import std.io
import std.iter (Stream)
import std.json (Json)
import std.stdio (Stderr)
import std.string (StringBuffer, ToString)
import std.sync (Channel)
import std.sys (exit)
import std.time (DateTime)
import wobsite.fnmatch
import wobsite.time (parse_date)
import wobsite.url (file_url, relative_to_absolute)

let INDEX_FILE = 'index.md'

# A type that maps asset paths/URIs to their checksums/hashes.
class Hashes {
  # The keys of this map start with a `/`, such that relative URLs such as
  # `/css/foo.css` directly translate into valid keys for this map.
  let @mapping: Map[String, String]

  fn static new -> Hashes {
    Hashes(Map.new)
  }

  fn mut add(path: Path, key: String) -> Result[Nil, io.Error] {
    let bytes = ByteArray.new
    let file = try ReadOnlyFile.new(path)
    let hasher = Sha256.new

    while (try file.read(into: bytes, size: 8096)) > 0 {
      hasher.write(bytes)
      bytes.clear
    }

    @mapping.set(key, hasher.finish.to_string)
    Result.Ok(nil)
  }

  fn get(key: String) -> Option[String] {
    @mapping.opt(key)
  }
}

impl Clone[Hashes] for Hashes {
  fn pub clone -> Hashes {
    Hashes(
      @mapping.iter.reduce(Map.new, fn (map, pair) {
        map.set(pair.key.clone, pair.value.clone)
        map
      }),
    )
  }
}

# An error that may be produced when parsing JSON front matter.
class pub enum FrontMatterError {
  # The JSON syntax is invalid.
  case InvalidJson(String)

  # A required key is missing or invalid.
  case InvalidKey(String)
}

impl ToString for FrontMatterError {
  fn pub to_string -> String {
    match self {
      case InvalidJson(v) -> 'the JSON front matter is invalid: ${v}'
      case InvalidKey(v) -> "the key '${v}' is missing or invalid"
    }
  }
}

# An error that may be produced when parsing a Markdown document.
class pub enum PageError {
  # An IO operation (such as reading the Markdown file) failed.
  #
  # The arguments of this case are:
  #
  # 1. The path of the file that couldn't be parsed
  # 1. The IO error that occurred
  case Io(Path, io.Error)

  # The JSON front matter is invalid.
  #
  # The arguments of this case are:
  #
  # 1. The path of the file that couldn't be parsed
  # 1. The error produced while parsing the front matter.
  case FrontMatter(Path, FrontMatterError)

  # The Markdown is invalid.
  #
  # The arguments of this case are:
  #
  # 1. The path of the file that couldn't be parsed
  # 1. An error message produced while parsing the Markdown
  case Markdown(Path, String)
}

impl ToString for PageError {
  fn pub to_string -> String {
    match self {
      case Io(p, e) -> 'failed to read ${p}: ${e}'
      case FrontMatter(p, InvalidJson(m)) -> {
        'failed to parse the front matter of ${p}: ${m}'
      }
      case FrontMatter(p, m) -> 'failed to parse the front matter of ${p}: ${m}'
      case Markdown(p, v) -> 'failed to parse the Markdown of ${p}: ${v}'
    }
  }
}

# A type storing the parsed front matter of a document.
class pub FrontMatter {
  # The title of the page.
  let pub @title: String

  # The date at which the page is created.
  let pub @date: DateTime

  # Parses JSON front matter from a `String`.
  fn pub static parse(string: String) -> Result[FrontMatter, FrontMatterError] {
    let json = try Json.parse(string).map_error(fn (e) {
      FrontMatterError.InvalidJson(e.to_string)
    })

    let title = match json.query.key('title').as_string {
      case Some(v) -> v
      case _ -> throw FrontMatterError.InvalidKey('title')
    }

    let date = match json.query.key('date').as_string {
      case Some(v) -> {
        match parse_date(v) {
          case Some(v) -> v
          case _ -> throw FrontMatterError.InvalidKey('date')
        }
      }
      case _ -> DateTime.utc
    }

    Result.Ok(FrontMatter(title: title, date: date))
  }
}

# A page backed by a Markdown document.
class pub Page {
  # The JSON front matter.
  let pub @front_matter: FrontMatter

  # The URL of the page.
  let pub @url: String

  # The path to the source file of this page.
  let pub @source_path: Path

  # The body of the page.
  let pub @body: markdown.Document

  # Parses a `Page` from a source file path.
  #
  # The `source` argument is the path to the main source directory. The `path`
  # argument is the path to the source file (inside the `source` directory) that
  # needs to be parsed.
  fn pub static parse_file(
    source: ref Path,
    path: ref Path,
  ) -> Result[Page, PageError] {
    let url = file_url(source, path)
    let data = ByteArray.new

    try ReadOnlyFile
      .new(path.clone)
      .then(fn (f) { f.read_all(data) })
      .map_error(fn (e) { PageError.Io(path.clone, e) })

    let front_md = markdown.split_front_matter(data.into_string)
    let front = try FrontMatter.parse(front_md.0).map_error(fn (e) {
      PageError.FrontMatter(path.clone, e)
    })

    let doc = try markdown.Document.parse(front_md.1).map_error(fn (e) {
      PageError.Markdown(path.clone, e.to_string)
    })

    Result.Ok(
      Page(front_matter: front, url: url, source_path: path.clone, body: doc),
    )
  }

  # Returns the title of the page.
  fn pub title -> String {
    @front_matter.title
  }

  # Returns the date at which the page is created.
  fn pub date -> ref DateTime {
    @front_matter.date
  }

  # Converts the Markdown to an HTML document.
  #
  # The `filters` array is a list of Markdown filters to apply to the HTML
  # document.
  fn pub to_html(filters: Array[Filter]) -> html.Document {
    let doc = @body.to_html

    filters.into_iter.each(fn (filter) { filter.run(doc) })
    doc
  }
}

# A type that tracks the source and output directories, along with all the
# source files.
class pub Files {
  # The directory containing the source files.
  let pub @source: Path

  # The directory to store the built files in.
  let pub @output: Path

  # A list of all the files in the source directory.
  let @files: Array[Path]

  # A mapping of paths relative to the source directory and their corresponding
  # file hashes.
  let @hashes: Hashes

  # Returns a new `Files` using the given source and output directories.
  #
  # This method recursively crawls the `source` directory, recording all the
  # source files it encounters. If this fails, an `Error(io.Error)` is returned.
  fn static new(source: Path, output: Path) -> Result[Files, io.Error] {
    let files = []
    let hashes = Hashes.new
    let iter = try source.list_all

    try iter.try_each(fn (res) {
      match res {
        case Ok({ @type = File, @path = path }) -> {
          try hashes.add(path.clone, '/${path.strip_prefix(source).get}')
          files.push(path)
          Result.Ok(nil)
        }
        case Ok(_) -> Result.Ok(nil)
        case Error(e) -> Result.Error(e)
      }
    })

    Result.Ok(
      Files(source: source, output: output, files: files, hashes: hashes),
    )
  }

  # Returns an iterator that yields all the source files matching the given
  # `fnmatch(3)` pattern.
  fn pub matching(pattern: String) -> Stream[ref Path] {
    let root = pattern.starts_with?('/')

    @files.iter.select(fn (path) {
      fnmatch.match(pattern, '/${path.strip_prefix(@source).get}', root)
    })
  }

  fn hash(path: ref String) -> Option[String] {
    @hashes.get(path)
  }
}

impl Clone[Files] for Files {
  fn pub clone -> Files {
    Files(
      source: @source.clone,
      output: @output.clone,
      files: @files.clone,
      hashes: @hashes.clone,
    )
  }
}

# A collection of errors produced while building the website, along with the
# means of easily formatting them.
class pub Errors {
  let @entries: Array[(Path, String)]

  fn mut add(path: Path, error: String) {
    @entries.push((path, error))
  }

  fn empty? -> Bool {
    @entries.empty?
  }
}

impl ToString for Errors {
  fn pub to_string -> String {
    let buf = @entries.iter.reduce(StringBuffer.new, fn (buf, entry) {
      if buf.size > 0 { buf.push('\n\n') }

      buf.push('${entry.0} \e[31;1merror:\e[0m\n  ${entry.1}')
      buf
    })

    buf.into_string
  }
}

# A type that updates an HTML document such that asset links (e.g. CSS files)
# contain a hash, ensuring that updates bust browser caches.
#
# This type doesn't physically rename any files, instead it adds a `?hash=VAL`
# query string to each relevant asset link.
class pub UpdateAssetLinks {
  let @files: ref Files
  let @url: String

  # Returns a new `UpdateAssetLinks`.
  #
  # The `files` argument is the list of site files to use when updating links.
  #
  # The `url` argument is the relative URL of the page that's being processed.
  fn pub static new(files: ref Files, url: String) -> UpdateAssetLinks {
    UpdateAssetLinks(files, url)
  }

  # Updates any asset links in the given HTML document.
  fn pub run(document: mut html.Document) {
    let nodes = document.nodes.iter_mut.to_array

    loop {
      match nodes.pop {
        case Some(Element(el)) -> {
          element(el)
          nodes.append(el.nodes.iter_mut.to_array)
        }
        case Some(_) -> {}
        case _ -> break
      }
    }
  }

  fn element(element: mut html.Element) {
    match element.name {
      case 'link' -> link(element)
      case 'img' -> src_element(element)
      case 'script' -> src_element(element)
      case _ -> {}
    }
  }

  fn src_element(element: mut html.Element) {
    match element.attributes.opt('src') {
      case Some(url) -> element.attr('src', hashed_url(url))
      case _ -> return
    }
  }

  fn link(link: mut html.Element) {
    match link.attributes.opt('rel') {
      case Some('stylesheet' or 'icon' or 'preload') -> {
        match link.attributes.opt('href') {
          case Some(url) -> link.attr('href', hashed_url(url))
          case _ -> return
        }
      }
      case _ -> return
    }
  }

  fn hashed_url(url: String) -> String {
    let key = if url.starts_with?('/').false? {
      relative_to_absolute(@url, url, as_file: true)
    } else {
      url
    }

    match @files.hash(key) {
      case Some(v) -> '${url}?hash=${v}'
      case _ -> url
    }
  }
}

# A type that represents a website to build.
class pub Site {
  # The files and directories that make up the website.
  let pub @files: Files

  # The number of pending jobs.
  let @pending: Int

  # A channel used to communicate the result of each job.
  let @status: Channel[uni Status]

  # Creates a new `Site`, builds it, and presents the user with the results.
  #
  # The `func` argument is used to set up what files to build, copy, etc.
  #
  # If any errors are produced, they're written to STDERR and this method
  # terminates the program with exit code 1.
  #
  # # Examples
  #
  # Building a website that consists of simple text and CSS files:
  #
  # ```
  # import wobsite (Site)
  #
  # Site.build(fn (site) {
  #   site.copy('*.txt')
  #   site.copy('*.css')
  # })
  # ```
  fn pub static build(func: fn (mut Site)) {
    let source = Path.new('source')
    let output = Path.new('public')
    let stderr = Stderr.new
    let site = match Site.new(source, output) {
      case Ok(site) -> site
      case Error(e) -> {
        stderr.print("Failed to get the site's source files: ${e}")
        exit(1)
      }
    }

    func.call(site)

    match site.wait {
      case Ok(_) -> {}
      case Error(e) -> {
        stderr.print(e.to_string)
        exit(1)
      }
    }
  }

  # Returns a new `Site` instance.
  #
  # The `source` argument specifies the path to the source files. The `output`
  # argument is the path to write the built files to.
  #
  # This method also recursively gets all the source files to (potentially)
  # build. If this fails, an `Error(std.io.Error)` is returned.
  fn pub static new(source: Path, output: Path) -> Result[Site, io.Error] {
    Files.new(source, output).map(fn (files) {
      Site(files: files, pending: 0, status: Channel.new)
    })
  }

  # Schedule a job that generates an arbitrary file.
  #
  # The `path` argument specifies the output path, relative to the output
  # directory.
  #
  # The `builder` argument is a closure that's called to generate the content of
  # the file.
  #
  # # Examples
  #
  # ```
  # import wobsite (Site)
  #
  # Site.build(fn (site) {
  #   site.generate('feed.xml') fn (files) { 'Example content' }
  # })
  # ```
  fn pub mut generate(
    path: String,
    builder: uni fn (ref Files) -> Result[String, String],
  ) {
    @pending += 1
    spawn.generate(recover @files.output.join(path), builder)
  }

  # Copies a source file to the output directory, using the same hierarchy as
  # the source file.
  #
  # The `pattern` argument specifies the `fnmatch(3)` pattern to use for finding
  # the files to copy.
  #
  # # Examples
  #
  # ```inko
  # import wobsite (Site)
  #
  # Site.build(fn (site) { site.copy('*.css') })
  # ```
  fn pub mut copy(pattern: String) {
    @files.matching(pattern).each(fn (path) {
      @pending += 1
      spawn.copy(recover path.clone)
    })
  }

  # Generates an HTML file from a Markdown file.
  #
  # The `pattern` argument specifies the `fnmatch(3)` pattern to use for
  # determining the files to process.
  #
  # The `builder` argument is a closure called for every file to process,
  # returning another closure used to build the final HTML document. In a
  # typical setting, this closure converts the Markdown to HTML and wraps it in
  # a layout of sorts.
  #
  # Input files are mapped to output files as follows:
  #
  # - `./source/index.md` becomes `./public/index.html`
  # - `./source/foo.md` becomes `./public/foo/index.html`
  # - `./source/foo/bar/index.md` becomes `./public/foo/bar/index.html`
  # - `./source/foo/bar.md` becomes `./public/foo/bar/index.html`
  fn pub mut page(
    pattern: String,
    builder: fn -> uni fn (ref Files, Page) -> Result[html.Document, String],
  ) {
    @files.matching(pattern).each(fn (path) {
      @pending += 1
      spawn.page(recover path.clone, index: true, builder: builder.call)
    })
  }

  # Generates an HTML file from a Markdown file, without generating an
  # `index.html` file.
  #
  # See `Site.page` for more details.
  #
  # Input files are mapped to output files as follows:
  #
  # - `./source/index.md` becomes `./public/index.html`
  # - `./source/foo.md` becomes `./public/foo.html`
  # - `./source/foo/bar/index.md` becomes `./public/foo/bar.html`
  # - `./source/foo/bar.md` becomes `./public/foo/bar.html`
  fn pub mut page_without_index(
    pattern: String,
    builder: fn -> uni fn (ref Files, Page) -> Result[html.Document, String],
  ) {
    @files.matching(pattern).each(fn (path) {
      @pending += 1
      spawn.page(recover path.clone, index: false, builder: builder.call)
    })
  }

  # Waits for the site to be built, returning once all pages have been
  # processed.
  #
  # If one or more pages failed to build, a `Result.Error` is returned.
  fn pub move wait -> Result[Nil, Errors] {
    let errors = Errors([])

    while @pending > 0 {
      match @status.receive {
        case Ok -> {}
        case Error(path, err) -> errors.add(path, err)
      }

      @pending -= 1
    }

    if errors.empty? { Result.Ok(nil) } else { Result.Error(errors) }
  }

  fn spawn -> Worker {
    Worker(files: recover @files.clone, status: recover @status.clone)
  }
}

# The result of a background job.
class pub enum Status {
  # The job finished successfully.
  case Ok

  # The job failed.
  #
  # The arguments of this case are as follows:
  #
  # 1. The path of the file that the error belongs to
  # 1. An error message
  case Error(Path, String)
}

class async Worker {
  let @files: Files
  let @status: Channel[uni Status]

  fn async generate(
    path: uni Path,
    builder: uni fn (ref Files) -> Result[String, String],
  ) {
    let path = recover path
    let data = match builder.call(@files) {
      case Ok(v) -> v
      case Error(e) -> {
        @status.send(recover Status.Error(path.clone, e))
        return
      }
    }

    let res = path
      .directory
      .create_directory_all
      .then(fn (_) { WriteOnlyFile.new(path.clone) })
      .then(fn (f) { f.write_string(data) })

    let status = match res {
      case Ok(_) -> recover Status.Ok
      case Error(e) -> recover Status.Error(path.clone, e.to_string)
    }

    @status.send(status)
  }

  fn async copy(from: uni Path) {
    let from = recover from
    let to = @files.output.join(from.strip_prefix(@files.source).get)
    let dir = to.directory
    let status = match dir.create_directory_all.then(fn (_) { from.copy(to) }) {
      case Ok(_) -> recover Status.Ok
      case Error(e) -> recover Status.Error(to.clone, e.to_string)
    }

    @status.send(status)
  }

  fn async page(
    source: uni Path,
    index: Bool,
    builder: uni fn (ref Files, Page) -> Result[html.Document, String],
  ) {
    let source = recover source
    let rel_source = source.strip_prefix(@files.source).get
    let target = if rel_source.tail == INDEX_FILE or index.false? {
      @files.output.join(rel_source.with_extension('html'))
    } else {
      @files.output.join(rel_source.with_extension('').join('index.html'))
    }

    let page = match Page.parse_file(@files.source, source) {
      case Ok(v) -> v
      case Error(e) -> {
        @status.send(recover Status.Error(target.clone, e.to_string))
        return
      }
    }

    let url = page.url
    let html = match builder.call(@files, page) {
      case Ok(v) -> v
      case Error(e) -> {
        @status.send(recover Status.Error(target.clone, e))
        return
      }
    }

    UpdateAssetLinks.new(@files, url).run(html)

    let status = match
      target
        .directory
        .create_directory_all
        .then(fn (_) { WriteOnlyFile.new(target.clone) })
        .then(fn (f) { f.write_string(html.to_string) })
    {
      case Ok(_) -> recover Status.Ok
      case Error(e) -> recover Status.Error(target.clone, e.to_string)
    }

    @status.send(status)
  }
}
